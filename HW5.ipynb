{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECGR 4105 HW5: Neural Networks\n",
    "# Author: Lucas Therrien\n",
    "# Student ID #801122089\n",
    "# GitHub Link: https://github.com/lucastherrien/ECGR4105HW5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##_________________________________________##\n",
    "## Setup\n",
    "##_________________________________________##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nbconvert\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, SVR\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import optim\n",
    "#Suppress all warnings because they annoy me\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##_________________________________________##\n",
    "## Problem 1\n",
    "##_________________________________________##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.5700],\n",
      "        [5.5900],\n",
      "        [5.8200],\n",
      "        [8.1900],\n",
      "        [5.6300],\n",
      "        [4.8900],\n",
      "        [3.3900],\n",
      "        [2.1800],\n",
      "        [4.8400],\n",
      "        [6.0400],\n",
      "        [6.8400]])\n"
     ]
    }
   ],
   "source": [
    "# model eq: w2 * t_u ** 2 + w1 * t_u + b\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_c = torch.tensor(t_c).unsqueeze(1)\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_u = torch.tensor(t_u).unsqueeze(1)\n",
    "t_un = 0.1*t_u\n",
    "print(t_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2nd_order(t_u, w1, w2, b):\n",
    "    return w2 * t_u ** 2 + w1 * t_u + b\n",
    "\n",
    "def model_1st_order(t_u, w1, b):\n",
    "    return w1 * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)  # <1>\n",
    "    return dsq_diffs\n",
    "\n",
    "def dmodel_dw2(t_u):\n",
    "    return t_u**2\n",
    "\n",
    "def dmodel_dw1(t_u):\n",
    "    return t_u\n",
    "\n",
    "def grad_fn_2nd_order(t_u, t_c, t_p):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw2 = dloss_dtp * dmodel_dw2(t_u)\n",
    "    dloss_dw1 = dloss_dtp * dmodel_dw1(t_u)\n",
    "    dloss_db = dloss_dtp * 1\n",
    "    return torch.stack([dloss_dw2.sum(), dloss_dw1.sum(), dloss_db.sum()])  # <1>\n",
    "\n",
    "def training_loop_2nd_order(n_epochs,params,lr,loss_fn,t_u,t_c):\n",
    "    loss_hist = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        w2, w1, b = params\n",
    "        #t_u_train, t_u_val, t_c_train, t_c_val = train_test_split(t_u, t_c, test_size = 0.2)\n",
    "        t_p = model_2nd_order(t_u,w2=w2,w1=w1,b=b)\n",
    "        loss = loss_fn(t_p,t_c)\n",
    "        grad = grad_fn_2nd_order(t_u, t_c, t_p)\n",
    "        params = params - lr * grad\n",
    "        \n",
    "        if epoch == 1 or epoch % 500 == 0:\n",
    "            #print(f\"Epoch {epoch}\",f\"Training Loss {loss_train}\",f\"Val Loss {loss_val}\")\n",
    "            loss_hist.append(loss)\n",
    "            print(f\"Epoch {epoch}\",f\"Loss {loss}\")\n",
    "            print(f\"Params {params}\", f\"Grad {grad}\")\n",
    "    return loss_hist\n",
    "        \n",
    "\n",
    "def grad_fn_1st_order(t_u, t_c, t_p):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw1 = dloss_dtp * dmodel_dw1(t_u)\n",
    "    dloss_db = dloss_dtp * 1\n",
    "    return torch.stack([dloss_dw1.sum(), dloss_db.sum()])  # <1>\n",
    "\n",
    "def training_loop_1st_order(n_epochs,params,lr,loss_fn,t_u,t_c):\n",
    "    loss_hist = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        w1, b = params\n",
    "        #t_u_train, t_u_val, t_c_train, t_c_val = train_test_split(t_u, t_c, test_size = 0.2)\n",
    "        t_p = model_1st_order(t_u,w1=w1,b=b)\n",
    "        loss = loss_fn(t_p,t_c)\n",
    "        grad = grad_fn_1st_order(t_u, t_c, t_p)\n",
    "        params = params - lr * grad\n",
    "        \n",
    "        if epoch == 1 or epoch % 500 == 0:\n",
    "            #print(f\"Epoch {epoch}\",f\"Training Loss {loss_train}\",f\"Val Loss {loss_val}\")\n",
    "            loss_hist.append(loss)\n",
    "            print(f\"Epoch {epoch}\",f\"Loss {loss}\")\n",
    "            print(f\"Params {params}\", f\"Grad {grad}\")\n",
    "    return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 675.7943725585938\n",
      "Params tensor([ 0.8260,  0.9720, -0.0048]) Grad tensor([1739.5315,  279.6790,   48.1760])\n",
      "Epoch 500 Loss 10.708597183227539\n",
      "Params tensor([ 0.3155,  0.5400, -0.1712]) Grad tensor([-1.0579,  6.3023,  2.8121])\n",
      "Epoch 1000 Loss 8.642083168029785\n",
      "Params tensor([ 0.3641,  0.2507, -0.3015]) Grad tensor([-0.8909,  5.2993,  2.4124])\n",
      "Epoch 1500 Loss 7.1710052490234375\n",
      "Params tensor([ 0.4050,  0.0076, -0.4135]) Grad tensor([-0.7498,  4.4535,  2.0753])\n",
      "Epoch 2000 Loss 6.123476028442383\n",
      "Params tensor([ 0.4395, -0.1967, -0.5099]) Grad tensor([-0.6310,  3.7401,  1.7909])\n",
      "Epoch 2500 Loss 5.377227783203125\n",
      "Params tensor([ 0.4684, -0.3683, -0.5933]) Grad tensor([-0.5307,  3.1385,  1.5510])\n",
      "Epoch 3000 Loss 4.845285892486572\n",
      "Params tensor([ 0.4928, -0.5121, -0.6656]) Grad tensor([-0.4462,  2.6311,  1.3486])\n",
      "Epoch 3500 Loss 4.465786933898926\n",
      "Params tensor([ 0.5133, -0.6326, -0.7286]) Grad tensor([-0.3750,  2.2032,  1.1778])\n",
      "Epoch 4000 Loss 4.194724082946777\n",
      "Params tensor([ 0.5305, -0.7335, -0.7838]) Grad tensor([-0.3147,  1.8423,  1.0337])\n",
      "Epoch 4500 Loss 4.0008015632629395\n",
      "Params tensor([ 0.5449, -0.8178, -0.8324]) Grad tensor([-0.2640,  1.5380,  0.9122])\n",
      "Epoch 5000 Loss 3.8617441654205322\n",
      "Params tensor([ 0.5570, -0.8881, -0.8753]) Grad tensor([-0.2213,  1.2814,  0.8096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(675.7944),\n",
       " tensor(10.7086),\n",
       " tensor(8.6421),\n",
       " tensor(7.1710),\n",
       " tensor(6.1235),\n",
       " tensor(5.3772),\n",
       " tensor(4.8453),\n",
       " tensor(4.4658),\n",
       " tensor(4.1947),\n",
       " tensor(4.0008),\n",
       " tensor(3.8617)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate 0.0001\n",
    "w2 = 1\n",
    "w1 = 1\n",
    "b = 0\n",
    "training_loop_2nd_order(n_epochs=5000,params=torch.tensor([w2,w1,b]),lr=0.0001,loss_fn=loss_fn,t_c=t_c,t_u=t_un)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 675.7943725585938\n",
      "Params tensor([-0.7395,  0.7203, -0.0482]) Grad tensor([1739.5315,  279.6790,   48.1760])\n",
      "Epoch 500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 1000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 1500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 2000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 2500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 3000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 3500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 4000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 4500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 5000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(675.7944),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate 0.001\n",
    "w2 = 1\n",
    "w1 = 1\n",
    "b = 0\n",
    "training_loop_2nd_order(n_epochs=5000,params=torch.tensor([w2,w1,b]),lr=0.001,loss_fn=loss_fn,t_c=t_c,t_u=t_un)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 675.7943725585938\n",
      "Params tensor([-16.3953,  -1.7968,  -0.4818]) Grad tensor([1739.5315,  279.6790,   48.1760])\n",
      "Epoch 500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 1000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 1500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 2000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 2500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 3000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 3500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 4000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 4500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 5000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(675.7944),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate 0.01\n",
    "w2 = 1\n",
    "w1 = 1\n",
    "b = 0\n",
    "training_loop_2nd_order(n_epochs=5000,params=torch.tensor([w2,w1,b]),lr=0.01,loss_fn=loss_fn,t_c=t_c,t_u=t_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 675.7943725585938\n",
      "Params tensor([-172.9532,  -26.9679,   -4.8176]) Grad tensor([1739.5315,  279.6790,   48.1760])\n",
      "Epoch 500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 1000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 1500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 2000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 2500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 3000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 3500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 4000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 4500 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n",
      "Epoch 5000 Loss nan\n",
      "Params tensor([nan, nan, nan]) Grad tensor([nan, nan, nan])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(675.7944),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan),\n",
       " tensor(nan)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate 0.1\n",
    "w2 = 1\n",
    "w1 = 1\n",
    "b = 0\n",
    "training_loop_2nd_order(n_epochs=5000,params=torch.tensor([w2,w1,b]),lr=0.1,loss_fn=loss_fn,t_c=t_c,t_u=t_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the model with a 0.0001 learning rate is the only functional model, it is clearly the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 675.7943725585938\n",
      "Params tensor([ 0.8260,  0.9720, -0.0048]) Grad tensor([1739.5315,  279.6790,   48.1760])\n",
      "Epoch 500 Loss 10.708597183227539\n",
      "Params tensor([ 0.3155,  0.5400, -0.1712]) Grad tensor([-1.0579,  6.3023,  2.8121])\n",
      "Epoch 1000 Loss 8.642083168029785\n",
      "Params tensor([ 0.3641,  0.2507, -0.3015]) Grad tensor([-0.8909,  5.2993,  2.4124])\n",
      "Epoch 1500 Loss 7.1710052490234375\n",
      "Params tensor([ 0.4050,  0.0076, -0.4135]) Grad tensor([-0.7498,  4.4535,  2.0753])\n",
      "Epoch 2000 Loss 6.123476028442383\n",
      "Params tensor([ 0.4395, -0.1967, -0.5099]) Grad tensor([-0.6310,  3.7401,  1.7909])\n",
      "Epoch 2500 Loss 5.377227783203125\n",
      "Params tensor([ 0.4684, -0.3683, -0.5933]) Grad tensor([-0.5307,  3.1385,  1.5510])\n",
      "Epoch 3000 Loss 4.845285892486572\n",
      "Params tensor([ 0.4928, -0.5121, -0.6656]) Grad tensor([-0.4462,  2.6311,  1.3486])\n",
      "Epoch 3500 Loss 4.465786933898926\n",
      "Params tensor([ 0.5133, -0.6326, -0.7286]) Grad tensor([-0.3750,  2.2032,  1.1778])\n",
      "Epoch 4000 Loss 4.194724082946777\n",
      "Params tensor([ 0.5305, -0.7335, -0.7838]) Grad tensor([-0.3147,  1.8423,  1.0337])\n",
      "Epoch 4500 Loss 4.0008015632629395\n",
      "Params tensor([ 0.5449, -0.8178, -0.8324]) Grad tensor([-0.2640,  1.5380,  0.9122])\n",
      "Epoch 5000 Loss 3.8617441654205322\n",
      "Params tensor([ 0.5570, -0.8881, -0.8753]) Grad tensor([-0.2213,  1.2814,  0.8096])\n",
      "Epoch 1 Loss 80.36434173583984\n",
      "Params tensor([1.0078, 0.0011]) Grad tensor([-77.6140, -10.6400])\n",
      "Epoch 500 Loss 29.505889892578125\n",
      "Params tensor([2.2366, 0.0656]) Grad tensor([-4.2259,  2.2983])\n",
      "Epoch 1000 Loss 28.94377326965332\n",
      "Params tensor([ 2.3204, -0.0712]) Grad tensor([-0.6942,  2.8964])\n",
      "Epoch 1500 Loss 28.505281448364258\n",
      "Params tensor([ 2.3489, -0.2165]) Grad tensor([-0.5213,  2.9014])\n",
      "Epoch 2000 Loss 28.074451446533203\n",
      "Params tensor([ 2.3745, -0.3610]) Grad tensor([-0.5089,  2.8783])\n",
      "Epoch 2500 Loss 27.650876998901367\n",
      "Params tensor([ 2.3999, -0.5043]) Grad tensor([-0.5042,  2.8540])\n",
      "Epoch 3000 Loss 27.23444366455078\n",
      "Params tensor([ 2.4250, -0.6464]) Grad tensor([-0.5002,  2.8299])\n",
      "Epoch 3500 Loss 26.82501983642578\n",
      "Params tensor([ 2.4499, -0.7873]) Grad tensor([-0.4962,  2.8059])\n",
      "Epoch 4000 Loss 26.422496795654297\n",
      "Params tensor([ 2.4745, -0.9270]) Grad tensor([-0.4919,  2.7822])\n",
      "Epoch 4500 Loss 26.02674674987793\n",
      "Params tensor([ 2.4990, -1.0655]) Grad tensor([-0.4875,  2.7587])\n",
      "Epoch 5000 Loss 25.637672424316406\n",
      "Params tensor([ 2.5233, -1.2029]) Grad tensor([-0.4835,  2.7353])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x163bf06be50>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparison with linear model\n",
    "w2 = 1\n",
    "w1 = 1\n",
    "b = 0\n",
    "nonLinLoss = training_loop_2nd_order(n_epochs=5000,params=torch.tensor([w2,w1,b]),lr=0.0001,loss_fn=loss_fn,t_c=t_c,t_u=t_un)\n",
    "w1 = 1\n",
    "b = 0\n",
    "linLoss = training_loop_1st_order(n_epochs=5000,params=torch.tensor([w1,b]),lr=0.0001,loss_fn=loss_fn,t_c=t_c,t_u=t_un)\n",
    "plt.plot(range(0, 11), nonLinLoss, color='blue') \n",
    "plt.plot(range(0, 11), linLoss, color='red') \n",
    "plt.rcParams[\"figure.figsize\"] = (10,6) \n",
    "plt.grid() \n",
    "plt.xlabel('Epochs x 500') \n",
    "plt.ylabel('Loss') \n",
    "plt.title('Linear vs Nonlinear loss') \n",
    "plt.legend(['Nonlinear Model','Linear Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nonlinear model converges to a smaller loss value, making it the superior model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##_________________________________________##\n",
    "## Problem 2\n",
    "##_________________________________________##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.42e+01 4.00e-02 2.00e-02 3.00e-02 2.00e-02]\n",
      " [8.96e+01 4.00e-02 4.00e-02 4.00e-02 3.00e-02]\n",
      " [9.96e+01 3.00e-02 2.00e-02 2.00e-02 2.00e-02]\n",
      " [7.50e+01 4.00e-02 2.00e-02 2.00e-02 3.00e-02]\n",
      " [7.42e+01 4.00e-02 1.00e-02 2.00e-02 2.00e-02]]\n",
      "[[13.3  ]\n",
      " [12.25 ]\n",
      " [12.25 ]\n",
      " [12.215]\n",
      " [11.41 ]]\n"
     ]
    }
   ],
   "source": [
    "# Input variables, standized and normalized sets\n",
    "hd = pd.read_csv('Housing.csv')\n",
    "x = hd[['area', 'bedrooms', 'bathrooms', 'stories', 'parking']]\n",
    "xn = np.array(x*0.01)\n",
    "print(xn[0:5])\n",
    "y = hd[['price']]\n",
    "yn = np.array(y*.000001)\n",
    "print(yn[0:5])\n",
    "x_train, x_test, y_train, y_test = train_test_split(xn, yn, test_size = 0.2)\n",
    "x_train = torch.from_numpy(x_train)\n",
    "x_train = x_train.unsqueeze(1)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "x_test = x_test.unsqueeze(1)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_train = y_train.unsqueeze(1)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_test = y_test.unsqueeze(1)\n",
    "#print(y_test)\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
    "                  t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train.float())\n",
    "        loss_train = loss_fn(t_p_train, t_c_train.float())\n",
    "        t_p_val = model(t_u_val.float()) \n",
    "        loss_val = loss_fn(t_p_val, t_c_val.float())\n",
    "        #val_acc = torch.sum(t_p_val == t_c_val.float())\n",
    "        #val_acc = val_acc/t_c_val.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")#,f\"Validation Accuracy {val_acc.item():.4f}\")\n",
    "            #print(t_p_val)\n",
    "            #print(t_c_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 201.0744, Validation loss 164.1078\n",
      "Epoch 1000, Training loss 3.2903, Validation loss 3.2647\n",
      "Epoch 2000, Training loss 3.2362, Validation loss 3.2297\n",
      "Epoch 3000, Training loss 3.1854, Validation loss 3.1973\n",
      "Epoch 4000, Training loss 3.1375, Validation loss 3.1671\n",
      "Epoch 5000, Training loss 3.0926, Validation loss 3.1392\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) \n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.0001)\n",
    "linear_model\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = loss_fn,\n",
    "    t_u_train = x_train,\n",
    "    t_u_val = x_test, \n",
    "    t_c_train = y_train,\n",
    "    t_c_val = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 12.0808, Validation loss 13.6972\n",
      "Epoch 1000, Training loss nan, Validation loss nan\n",
      "Epoch 2000, Training loss nan, Validation loss nan\n",
      "Epoch 3000, Training loss nan, Validation loss nan\n",
      "Epoch 4000, Training loss nan, Validation loss nan\n",
      "Epoch 5000, Training loss nan, Validation loss nan\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) \n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.001)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = loss_fn,\n",
    "    t_u_train = x_train,\n",
    "    t_u_val = x_test, \n",
    "    t_c_train = y_train,\n",
    "    t_c_val = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 11.2619, Validation loss 7.8242\n",
      "Epoch 1000, Training loss nan, Validation loss nan\n",
      "Epoch 2000, Training loss nan, Validation loss nan\n",
      "Epoch 3000, Training loss nan, Validation loss nan\n",
      "Epoch 4000, Training loss nan, Validation loss nan\n",
      "Epoch 5000, Training loss nan, Validation loss nan\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) \n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.01)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = loss_fn,\n",
    "    t_u_train = x_train,\n",
    "    t_u_val = x_test, \n",
    "    t_c_train = y_train,\n",
    "    t_c_val = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 87.3155, Validation loss 85.3025\n",
      "Epoch 1000, Training loss nan, Validation loss nan\n",
      "Epoch 2000, Training loss nan, Validation loss nan\n",
      "Epoch 3000, Training loss nan, Validation loss nan\n",
      "Epoch 4000, Training loss nan, Validation loss nan\n",
      "Epoch 5000, Training loss nan, Validation loss nan\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) \n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.1)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = loss_fn,\n",
    "    t_u_train = x_train,\n",
    "    t_u_val = x_test, \n",
    "    t_c_train = y_train,\n",
    "    t_c_val = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A learning rate of 0.0001 was the most optimal for this model, as it was the only model not to grossly overfit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##_________________________________________##\n",
    "## Problem 3\n",
    "##_________________________________________##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Sequential(\n",
      "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
      "  (hidden_activation): Tanh()\n",
      "  (output_linear): Linear(in_features=8, out_features=5, bias=True)\n",
      ")>\n",
      "Epoch 1, Training loss 30.4283, Validation loss 32.0274\n",
      "Epoch 50, Training loss 4.0300, Validation loss 5.1518\n",
      "Epoch 100, Training loss 3.2306, Validation loss 4.2566\n",
      "Epoch 150, Training loss 3.2870, Validation loss 4.3116\n",
      "Epoch 200, Training loss 3.2865, Validation loss 4.3130\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
    "                  t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train.float()) # <1>\n",
    "\n",
    "        loss_train = loss_fn(t_p_train, t_c_train.float())\n",
    "        t_p_val = model(t_u_val.float()) # <1>\n",
    "        loss_val = loss_fn(t_p_val, t_c_val.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 5))\n",
    "]))\n",
    "\n",
    "print(seq_model.parameters)\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=0.01) \n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = x_train.float(),\n",
    "    t_u_val = x_test.float(), \n",
    "    t_c_train = y_train.float(),\n",
    "    t_c_val = y_test.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This neural net was slight less effective than the best linear regression model, \n",
    "#however it did slightly overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Sequential(\n",
      "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
      "  (hidden_activation): Tanh()\n",
      "  (hidden_linear2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (hidden_activation2): Tanh()\n",
      "  (output_linear): Linear(in_features=8, out_features=5, bias=True)\n",
      ")>\n",
      "Epoch 1, Training loss 26.2507, Validation loss 27.8016\n",
      "Epoch 50, Training loss 4.8800, Validation loss 6.0444\n",
      "Epoch 100, Training loss 3.3449, Validation loss 4.3984\n",
      "Epoch 150, Training loss 3.2821, Validation loss 4.3137\n",
      "Epoch 200, Training loss 3.2621, Validation loss 4.2836\n"
     ]
    }
   ],
   "source": [
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('hidden_linear2', nn.Linear(8, 8)),\n",
    "    ('hidden_activation2', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 5))\n",
    "]))\n",
    "\n",
    "print(seq_model.parameters)\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=0.01) \n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = x_train.float(),\n",
    "    t_u_val = x_test.float(), \n",
    "    t_c_train = y_train.float(),\n",
    "    t_c_val = y_test.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model seems marginally more effective than the previous without running into apparent overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c3fdd1ba6fa6149e0a55b9d95e637df8fd62d3a04e8e673bb353b444f545e4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
